{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenAI from \"openai\";\n",
    "\n",
    "const openai = new OpenAI({\n",
    "    apiKey: env[\"OPENAI_API_KEY\"],\n",
    "    // baseURL: `https://${env[\"AZURE_OPENAI_API_INSTANCE_NAME\"]}.openai.azure.com/openai/deployments/${env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"]}`,\n",
    "    // defaultQuery: { 'api-version':  env[\"AZURE_OPENAI_API_VERSION\"] },\n",
    "    // defaultHeaders: { 'api-key': env[\"AZURE_OPENAI_API_KEY\"] },\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "const result = await openai.chat.completions.create({\n",
    "    model: 'gpt-3.5-turbo',\n",
    "    // model: env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"],\n",
    "    messages: [{ role: 'user', content: 'Say hello!' }],\n",
    "  });\n",
    "  console.log(result.choices[0]!.message?.content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getCurrentWeather({ location, unit=\"fahrenheit\"}){\n",
    "   const  weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return JSON.stringify(weather_info);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tools = [\n",
    "    {\n",
    "      type: \"function\",\n",
    "      function: {\n",
    "        name: \"getCurrentWeather\",\n",
    "        description: \"Get the current weather in a given location\",\n",
    "        parameters: {\n",
    "          type: \"object\",\n",
    "          properties: {\n",
    "            location: {\n",
    "              type: \"string\",\n",
    "              description: \"The city and state, e.g. San Francisco, CA\",\n",
    "            },\n",
    "            unit: { \n",
    "              type: \"string\", \n",
    "              enum: [\"celsius\", \"fahrenheit\"],\n",
    "              description: \"The unit of temperature\"\n",
    "            },\n",
    "          },\n",
    "          required: [\"location\", \"unit\"],\n",
    "        },\n",
    "      },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  id: \"chatcmpl-A8ij5QoqcjEFSazvxoPNxvkHwBN78\",\n",
      "  object: \"chat.completion\",\n",
      "  created: 1726641915,\n",
      "  model: \"gpt-3.5-turbo-0125\",\n",
      "  choices: [\n",
      "    {\n",
      "      index: 0,\n",
      "      message: {\n",
      "        role: \"assistant\",\n",
      "        content: null,\n",
      "        tool_calls: [ [Object] ],\n",
      "        refusal: null\n",
      "      },\n",
      "      logprobs: null,\n",
      "      finish_reason: \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  usage: {\n",
      "    prompt_tokens: 88,\n",
      "    completion_tokens: 20,\n",
      "    total_tokens: 108,\n",
      "    completion_tokens_details: { reasoning_tokens: 0 }\n",
      "  },\n",
      "  system_fingerprint: null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    " const messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        // \"content\": \"北京的天气怎么样\"\n",
    "        \"content\": \"What's the weather like in Redmond?\"\n",
    "\n",
    "    }\n",
    "]\n",
    "\n",
    "const result = await openai.chat.completions.create({\n",
    "    model: 'gpt-3.5-turbo',\n",
    "    // model: env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"],\n",
    "    messages,\n",
    "    tools\n",
    "  });\n",
    "  console.log(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  index: \u001b[33m0\u001b[39m,\n",
       "  message: {\n",
       "    role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "    content: \u001b[1mnull\u001b[22m,\n",
       "    tool_calls: [\n",
       "      {\n",
       "        id: \u001b[32m\"call_a2rsNtQlQXgirlf35z78h2A0\"\u001b[39m,\n",
       "        type: \u001b[32m\"function\"\u001b[39m,\n",
       "        function: {\n",
       "          name: \u001b[32m\"getCurrentWeather\"\u001b[39m,\n",
       "          arguments: \u001b[32m'{\"location\":\"Redmond\",\"unit\":\"celsius\"}'\u001b[39m\n",
       "        }\n",
       "      }\n",
       "    ],\n",
       "    refusal: \u001b[1mnull\u001b[22m\n",
       "  },\n",
       "  logprobs: \u001b[1mnull\u001b[22m,\n",
       "  finish_reason: \u001b[32m\"tool_calls\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你好\"\n",
    "    }\n",
    "]\n",
    "\n",
    "const result = await openai.chat.completions.create({\n",
    "    model: 'gpt-3.5-turbo',\n",
    "    // model: env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"],\n",
    "    messages,\n",
    "    tools,\n",
    "    tool_choice: {\n",
    "        type: \"function\",\n",
    "        function: {\n",
    "           name: \"getCurrentWeather\"\n",
    "        }\n",
    "    }\n",
    "  });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"temperature\":\"72\",\"unit\":\"fahrenheit\",\"forecast\":[\"sunny\",\"windy\"]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "const functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather\n",
    "  }\n",
    "\n",
    "const functionInfo = result.choices[0].message.tool_calls[0].function\n",
    "const functionName = functionInfo.name;\n",
    "const functionParams = functionInfo.arguments\n",
    "\n",
    "const functionResult = functions[functionName](functionParams);\n",
    "\n",
    "console.log(functionResult);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getCurrentTime({ format = \"iso\" } = {}) {\n",
    "    let currentTime;\n",
    "    switch (format) {\n",
    "        case \"iso\":\n",
    "            currentTime = new Date().toISOString();\n",
    "            break;\n",
    "        case \"locale\":\n",
    "            currentTime = new Date().toLocaleString();\n",
    "            break;\n",
    "        default:\n",
    "            currentTime = new Date().toString();\n",
    "            break;\n",
    "    }\n",
    "    return currentTime;\n",
    "}\n",
    "\n",
    "const tools = [\n",
    "    {\n",
    "        type: \"function\",\n",
    "        function: {\n",
    "            name: \"getCurrentTime\",\n",
    "            description: \"Get the current time in a given format\",\n",
    "            parameters: {\n",
    "                type: \"object\",\n",
    "                properties: {\n",
    "                    format: {\n",
    "                        type: \"string\",\n",
    "                        enum: [\"iso\", \"locale\", \"string\"],\n",
    "                        description: \"The format of the time, e.g. iso, locale, string\",\n",
    "                    },\n",
    "                },\n",
    "                required: [],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        type: \"function\",\n",
    "        function: {\n",
    "          name: \"getCurrentWeather\",\n",
    "          description: \"Get the current weather in a given location\",\n",
    "          parameters: {\n",
    "            type: \"object\",\n",
    "            properties: {\n",
    "              location: {\n",
    "                type: \"string\",\n",
    "                description: \"The city and state, e.g. San Francisco, CA\",\n",
    "              },\n",
    "              unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"] },\n",
    "            },\n",
    "            required: [\"location\", \"unit\"],\n",
    "          },\n",
    "        },\n",
    "      }\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "const messages = [\n",
    "    { role: \"user\", content: \" 上海 新疆 这三个城市的天气如何?\" },\n",
    "]\n",
    "\n",
    "const result = await openai.chat.completions.create({\n",
    "    model: 'gpt-3.5-turbo',\n",
    "    // model: env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"],\n",
    "    messages,\n",
    "    tools\n",
    "  });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  index: \u001b[33m0\u001b[39m,\n",
       "  message: {\n",
       "    role: \u001b[32m\"assistant\"\u001b[39m,\n",
       "    content: \u001b[1mnull\u001b[22m,\n",
       "    tool_calls: [\n",
       "      {\n",
       "        id: \u001b[32m\"call_9vNp68f5fBVNEqvWgs1FiuHP\"\u001b[39m,\n",
       "        type: \u001b[32m\"function\"\u001b[39m,\n",
       "        function: {\n",
       "          name: \u001b[32m\"getCurrentWeather\"\u001b[39m,\n",
       "          arguments: \u001b[32m'{\"location\": \"Shanghai\", \"unit\": \"celsius\"}'\u001b[39m\n",
       "        }\n",
       "      },\n",
       "      {\n",
       "        id: \u001b[32m\"call_lCdUC4yNVyWLwOFKMS5LHZXZ\"\u001b[39m,\n",
       "        type: \u001b[32m\"function\"\u001b[39m,\n",
       "        function: {\n",
       "          name: \u001b[32m\"getCurrentWeather\"\u001b[39m,\n",
       "          arguments: \u001b[32m'{\"location\": \"Xinjiang\", \"unit\": \"celsius\"}'\u001b[39m\n",
       "        }\n",
       "      }\n",
       "    ],\n",
       "    refusal: \u001b[1mnull\u001b[22m\n",
       "  },\n",
       "  logprobs: \u001b[1mnull\u001b[22m,\n",
       "  finish_reason: \u001b[32m\"tool_calls\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  { role: \"user\", content: \" 上海 新疆 这三个城市的天气如何?\" },\n",
      "  {\n",
      "    role: \"assistant\",\n",
      "    content: null,\n",
      "    tool_calls: [\n",
      "      {\n",
      "        id: \"call_9vNp68f5fBVNEqvWgs1FiuHP\",\n",
      "        type: \"function\",\n",
      "        function: {\n",
      "          name: \"getCurrentWeather\",\n",
      "          arguments: '{\"location\": \"Shanghai\", \"unit\": \"celsius\"}'\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        id: \"call_lCdUC4yNVyWLwOFKMS5LHZXZ\",\n",
      "        type: \"function\",\n",
      "        function: {\n",
      "          name: \"getCurrentWeather\",\n",
      "          arguments: '{\"location\": \"Xinjiang\", \"unit\": \"celsius\"}'\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    refusal: null\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_lCdUC4yNVyWLwOFKMS5LHZXZ",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "Error: 400 An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_lCdUC4yNVyWLwOFKMS5LHZXZ",
      "    at Function.generate (file:///Users/dfl/Library/Caches/deno/npm/registry.npmmirror.com/openai/4.29.2/error.mjs:40:20)",
      "    at OpenAI.makeStatusError (file:///Users/dfl/Library/Caches/deno/npm/registry.npmmirror.com/openai/4.29.2/core.mjs:256:25)",
      "    at OpenAI.makeRequest (file:///Users/dfl/Library/Caches/deno/npm/registry.npmmirror.com/openai/4.29.2/core.mjs:299:30)",
      "    at eventLoopTick (ext:core/01_core.js:168:7)",
      "    at async <anonymous>:17:18"
     ]
    }
   ],
   "source": [
    "\n",
    "messages.push(result.choices[0].message)\n",
    "\n",
    "const functions = {\n",
    "    \"getCurrentWeather\": getCurrentWeather\n",
    "  }\n",
    "\n",
    "const cell = result.choices[0].message.tool_calls[0]\n",
    "const functionInfo = cell.function\n",
    "const functionName = functionInfo.name;\n",
    "const functionParams = functionInfo.arguments\n",
    "const functionResult = functions[functionName](functionParams);\n",
    "\n",
    "console.log(messages);\n",
    "messages.push({\n",
    "  tool_call_id: cell.id,\n",
    "  role: \"tool\",\n",
    "  name: functionName,\n",
    "  content: functionResult,\n",
    "}); \n",
    "\n",
    "const response = await openai.chat.completions.create({\n",
    "  model: 'gpt-3.5-turbo',\n",
    "  // model: env[\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"],\n",
    "  messages,\n",
    "});\n",
    "console.log(response);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
