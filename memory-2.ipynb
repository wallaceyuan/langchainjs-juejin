{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d4e05f-8ab3-423e-826f-510c1d8d9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0df1a9-372e-42c3-b6e5-c899197ba7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我是小明\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: 我是小明\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.37s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" 你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \" 你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 37,\n",
      "                \"promptTokens\": 69,\n",
      "                \"totalTokens\": 106\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 37,\n",
      "      \"promptTokens\": 69,\n",
      "      \"totalTokens\": 106\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [1.37s] Exiting Chain run with output: {\n",
      "  \"response\": \" 你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "\n",
    "const chatModel = new ChatOpenAI();\n",
    "const memory = new BufferMemory();\n",
    "const chain = new ConversationChain({ llm: chatModel, memory: memory, verbose: true });\n",
    "const res1 = await chain.call({ input: \"我是小明\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c57bf9c-9ce9-411c-b7b6-cc55d6d8743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ response: \u001b[32m\" 你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\"\u001b[39m }"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493ac179-0863-4677-a69f-346a43436ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我叫什么？\",\n",
      "  \"history\": \"Human: 我是小明\\nAI:  你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 我是小明\\nAI:  你好小明！我是AI助手，很高兴与你交流。有什么可以帮助你的吗？\\nHuman: 我叫什么？\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [973ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你说你是小明，所以我会称呼你为小明。有什么我能帮助你的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你说你是小明，所以我会称呼你为小明。有什么我能帮助你的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 34,\n",
      "                \"promptTokens\": 119,\n",
      "                \"totalTokens\": 153\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 34,\n",
      "      \"promptTokens\": 119,\n",
      "      \"totalTokens\": 153\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [974ms] Exiting Chain run with output: {\n",
      "  \"response\": \"你说你是小明，所以我会称呼你为小明。有什么我能帮助你的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chain.call({ input: \"我叫什么？\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6253e8-40fb-4772-b781-168298085b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ response: \u001b[32m\"你说你是小明，所以我会称呼你为小明。有什么我能帮助你的吗？\"\u001b[39m }"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8077dc-9a9a-48c2-a13c-a88f2a94a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { BufferWindowMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const memory = new BufferWindowMemory({ k: 1 });\n",
    "const chain = new ConversationChain({ llm: model, memory: memory });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e70614-888b-431e-ab0b-9407cd670d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ConversationSummaryMemory } from \"langchain/memory\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const memory = new ConversationSummaryMemory({\n",
    "    memoryKey: \"summary\",\n",
    "    llm: new ChatOpenAI({\n",
    "          verbose: true,\n",
    "    }),\n",
    "  });\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const prompt = PromptTemplate.fromTemplate(`\n",
    "你是一个乐于助人的助手。尽你所能回答所有问题。\n",
    "\n",
    "这是聊天记录的摘要:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:`);\n",
    "const chain = new ConversationChain({ llm: model, prompt, memory, verbose: true });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21221a69-02c2-4bac-b27b-56ffcd015740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我是小明\",\n",
      "  \"summary\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\n你是一个乐于助人的助手。尽你所能回答所有问题。\\n\\n这是聊天记录的摘要:\\n\\nHuman: 我是小明\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.13s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"  你好小明，请问有什么可以帮助你的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"  你好小明，请问有什么可以帮助你的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 22,\n",
      "                \"promptTokens\": 54,\n",
      "                \"totalTokens\": 76\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 22,\n",
      "      \"promptTokens\": 54,\n",
      "      \"totalTokens\": 76\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n\\n\\nNew lines of conversation:\\nHuman: 我是小明\\nAI:   你好小明，请问有什么可以帮助你的吗？\\n\\nNew summary:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.17s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Human: I am Xiao Ming.\\nAI: Hello Xiao Ming, how can I help you?\\nThe human introduces himself as Xiao Ming and the AI greets him and asks how it can assist.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Human: I am Xiao Ming.\\nAI: Hello Xiao Ming, how can I help you?\\nThe human introduces himself as Xiao Ming and the AI greets him and asks how it can assist.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 39,\n",
      "                \"promptTokens\": 166,\n",
      "                \"totalTokens\": 205\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 39,\n",
      "      \"promptTokens\": 166,\n",
      "      \"totalTokens\": 205\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [2.31s] Exiting Chain run with output: {\n",
      "  \"response\": \"  你好小明，请问有什么可以帮助你的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chain.call({ input: \"我是小明\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d89513-faf5-4093-929b-76bc3a38a59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我叫什么？\",\n",
      "  \"summary\": \"Human: I am Xiao Ming.\\nAI: Hello Xiao Ming, how can I help you?\\nThe human introduces himself as Xiao Ming and the AI greets him and asks how it can assist.\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"\\n你是一个乐于助人的助手。尽你所能回答所有问题。\\n\\n这是聊天记录的摘要:\\nHuman: I am Xiao Ming.\\nAI: Hello Xiao Ming, how can I help you?\\nThe human introduces himself as Xiao Ming and the AI greets him and asks how it can assist.\\nHuman: 我叫什么？\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [864ms] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"您叫小明。有什么需要我帮助的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"您叫小明。有什么需要我帮助的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 20,\n",
      "                \"promptTokens\": 95,\n",
      "                \"totalTokens\": 115\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 20,\n",
      "      \"promptTokens\": 95,\n",
      "      \"totalTokens\": 115\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\nHuman: I am Xiao Ming.\\nAI: Hello Xiao Ming, how can I help you?\\nThe human introduces himself as Xiao Ming and the AI greets him and asks how it can assist.\\n\\nNew lines of conversation:\\nHuman: 我叫什么？\\nAI: 您叫小明。有什么需要我帮助的吗？\\n\\nNew summary:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.04s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The human asks \\\"What am I called?\\\" in Chinese, and the AI responds \\\"You are called Xiao Ming. Is there anything I can help you with?\\\"\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The human asks \\\"What am I called?\\\" in Chinese, and the AI responds \\\"You are called Xiao Ming. Is there anything I can help you with?\\\"\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 32,\n",
      "                \"promptTokens\": 206,\n",
      "                \"totalTokens\": 238\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 32,\n",
      "      \"promptTokens\": 206,\n",
      "      \"totalTokens\": 238\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [1.91s] Exiting Chain run with output: {\n",
      "  \"response\": \"您叫小明。有什么需要我帮助的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chain.call({ input: \"我叫什么？\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b988d5dd-bf44-4d52-8380-f179059694f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const memory = new ConversationSummaryBufferMemory({\n",
    "  llm: new ChatOpenAI(),\n",
    "  maxTokenLimit: 200\n",
    "});\n",
    "const chain = new ConversationChain({ llm: model, memory: memory, verbose: true });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c856db57-7ca2-4005-8160-54e0bf61c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我是小明\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: 我是小明\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.12s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"  你好，小明！我是AI助手，很高兴认识你。有什么可以帮助你的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"  你好，小明！我是AI助手，很高兴认识你。有什么可以帮助你的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 39,\n",
      "                \"promptTokens\": 69,\n",
      "                \"totalTokens\": 108\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 39,\n",
      "      \"promptTokens\": 69,\n",
      "      \"totalTokens\": 108\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count TypeError: client error (Connect)\n",
      "    at async mainFetch (ext:deno_fetch/26_fetch.js:170:12)\n",
      "    at async fetch (ext:deno_fetch/26_fetch.js:391:7)\n",
      "    at async RetryOperation._fn (file:///Users/dfl/Library/Caches/deno/npm/registry.npmmirror.com/p-retry/4.6.2/index.js:50:12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [2.25s] Exiting Chain run with output: {\n",
      "  \"response\": \"  你好，小明！我是AI助手，很高兴认识你。有什么可以帮助你的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res1 = await chain.call({ input: \"我是小明\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14948a02-2c4d-4269-9a81-aab2af9e3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我叫什么？\",\n",
      "  \"history\": \"Human: 我是小明\\nAI:   你好，小明！我是AI助手，很高兴认识你。有什么可以帮助你的吗？\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 我是小明\\nAI:   你好，小明！我是AI助手，很高兴认识你。有什么可以帮助你的吗？\\nHuman: 我叫什么？\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatOpenAI\u001b[22m\u001b[39m] [1.04s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你叫小明。很高兴认识你！有什么可以为你服务的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你叫小明。很高兴认识你！有什么可以为你服务的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"completionTokens\": 28,\n",
      "                \"promptTokens\": 120,\n",
      "                \"totalTokens\": 148\n",
      "              },\n",
      "              \"finish_reason\": \"stop\"\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"completionTokens\": 28,\n",
      "      \"promptTokens\": 120,\n",
      "      \"totalTokens\": 148\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count TypeError: client error (Connect)\n",
      "    at async mainFetch (ext:deno_fetch/26_fetch.js:170:12)\n",
      "    at async fetch (ext:deno_fetch/26_fetch.js:391:7)\n",
      "    at async RetryOperation._fn (file:///Users/dfl/Library/Caches/deno/npm/registry.npmmirror.com/p-retry/4.6.2/index.js:50:12)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [1.91s] Exiting Chain run with output: {\n",
      "  \"response\": \"你叫小明。很高兴认识你！有什么可以为你服务的吗？\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const res2 = await chain.call({ input: \"我叫什么？\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b750490-ee19-48c4-99b9-8d511d16ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { EntityMemory, ENTITY_MEMORY_CONVERSATION_TEMPLATE } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const model = new ChatOpenAI();\n",
    "const memory = new EntityMemory({\n",
    "    llm: new ChatOpenAI({\n",
    "        verbose: true \n",
    "    }),\n",
    "    chatHistoryKey: \"history\",\n",
    "    entitiesKey: \"entities\"\n",
    "});\n",
    "const chain = new ConversationChain({ \n",
    "    llm: model, \n",
    "    prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory: memory, \n",
    "    verbose: true \n",
    "});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8928d-c265-4f8d-b7be-ca770aa94ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "const res1 = await chain.call({ input: \"我叫小明，今年 18 岁\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d5d7ff-5e8b-4957-86a3-90680ead06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "const res2 = await chain.call({ input: \"ABC 是一家互联网公司，主要是售卖方便面的公司\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f215e7a-9d5d-4ebf-bfd5-386bf659dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "const res3 = await chain.call({ input: \"介绍小明\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e52d2ed-cb69-44f5-afd6-f1ac490af1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "const res3 = await chain.call({ input: \"介绍小明和 ABC\" });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf9f39-eed8-4662-af39-1f630350ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "const test1 = await memory.loadMemoryVariables({\n",
    "    input: \"介绍小明和 ABC\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac64626-1cb4-457a-ad56-a17ecf58d23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
